{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Science for Business - Data Science Consulting - Session 2 \n",
    "\n",
    "# Notebook 3: \n",
    "\n",
    "# Web Scraping with Scrapy: Getting reviews from TripAdvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.selector import Selector\n",
    "import sys\n",
    "from scrapy.http import Request\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# https://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "class HotelreviewsItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    rating = scrapy.Field()\n",
    "    review = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    trip_date = scrapy.Field()\n",
    "    trip_type = scrapy.Field()\n",
    "    published_date = scrapy.Field()\n",
    "    image_url = scrapy.Field()\n",
    "    hotel_type = scrapy.Field()\n",
    "    hotel_name = scrapy.Field()\n",
    "    hotel_adress = scrapy.Field()\n",
    "    price_range = scrapy.Field()\n",
    "    reviewer_id = scrapy.Field()\n",
    "    review_id = scrapy.Field()\n",
    "    review_language = scrapy.Field()\n",
    "    pid = scrapy.Field()\n",
    "    locid = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_info_splitter(raw_user_info):\n",
    "    \"\"\"\n",
    "\n",
    "    :param raw_user_info:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    user_info = {}\n",
    "\n",
    "    splited_info = raw_user_info.split()\n",
    "    for element in splited_info:\n",
    "        converted_element = get_convertible_elements_as_dic(element)\n",
    "        if converted_element:\n",
    "            user_info[converted_element[0]] = converted_element[1]\n",
    "\n",
    "    return user_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the JSon pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSon pipeline, you can rename the \"trust.jl\" to the name of your choice\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('tripadvisor2.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spider\n",
    "\n",
    "Now you know how to get data from one page, we want to automate the spider so it will crawl through all pages of reviews, ending with a full spider able to scrape every reviews of the selected parc. You will modify here the parse function since this is where you tell the spider to get the links and to follow them. <br>\n",
    "<b>To Do</b>: Complete the following code, to scrape all the reviews of one parc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySpider(CrawlSpider):\n",
    "    name = 'BasicSpider'\n",
    "    domain_url = \"https://www.tripadvisor.com\"\n",
    "    # allowed_domains = [\"https://www.tripadvisor.com\"]\n",
    "\n",
    "    start_urls = [\n",
    "\n",
    "        \"https://www.tripadvisor.fr/Hotel_Review-g1572451-d775381-Reviews-Center_Parcs_Le_Lac_d_Ailette-Chamouille_Aisne_Hauts_de_France.html\"]\n",
    "    \n",
    "        #Custom settings to modify settings usually found in the settings.py file \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'tripadvisor2.json'                        # Used for pipeline 2\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        open_span = '<span class=\"pageNum current disabled\">'\n",
    "        close_span = '</span>'\n",
    "        \n",
    "        all_review_pages = response.xpath(\"//a[contains(@class,'pageNum') and contains(@class,'last')]/@data-offset\").extract()\n",
    "\n",
    "#        next_reviews_page_url = \"https://www.tripadvisor.com\" + response.xpath(\"//a[contains(@class,'nav') and contains(@class,'next') and contains(@class,'primary')]/@href\").extract()[0]\n",
    "\n",
    "        next_page_number = 1+int(response.xpath('//span[@class=\"pageNum current disabled\"]').extract_first().replace(open_span, \"\").replace(close_span, \"\"))\n",
    "\n",
    "        if next_page_number < 1000:\n",
    "            yield scrapy.Request(next_reviews_page_url, callback=self.parse)\n",
    "\n",
    "        review_urls = []\n",
    "        for partial_review_url in response.xpath(\"//div[contains(@class,'quote')]/a/@href\").extract():\n",
    "            review_url = response.urljoin(partial_review_url)\n",
    "            if review_url not in review_urls:\n",
    "                review_urls.append(review_url)\n",
    "\n",
    "            yield scrapy.Request(review_url, callback=self.parse_review_page)\n",
    "\n",
    "    def parse_review_page(self, response):\n",
    "\n",
    "        item = HotelreviewsItem()\n",
    "\n",
    "        item[\"reviewer_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-memberid\").extract()),\n",
    "                                   None)\n",
    "        item[\"review_language\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-language\").extract()),\n",
    "                                       None)\n",
    "        item[\"review_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-reviewid\").extract()),\n",
    "                                 None)\n",
    "        item[\"review_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-reviewid\").extract()),\n",
    "                                 None)\n",
    "\n",
    "        item[\"pid\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-pid\").extract()),\n",
    "                           None)\n",
    "        item[\"locid\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-locid\").extract()),\n",
    "                             None)\n",
    "\n",
    "        review_id = item[\"review_id\"]\n",
    "        review_url_on_page = response.xpath('//script[@type=\"application/ld+json\"]/text()').extract()\n",
    "        review = eval(review_url_on_page[0])\n",
    "\n",
    "        item[\"review\"] = review[\"reviewBody\"].replace(\"\\\\n\", \"\")\n",
    "        item[\"title\"] = review[\"name\"]\n",
    "        item[\"rating\"] = review[\"reviewRating\"][\"ratingValue\"]\n",
    "        item[\"image_url\"] = review[\"image\"]\n",
    "        item[\"hotel_type\"] = review[\"itemReviewed\"][\"@type\"]\n",
    "        item[\"hotel_name\"] = review[\"itemReviewed\"][\"name\"]\n",
    "        item[\"price_range\"] = review[\"itemReviewed\"][\"priceRange\"]\n",
    "        item[\"hotel_adress\"] = review[\"itemReviewed\"][\"address\"]\n",
    "        try:\n",
    "            item[\"published_date\"] = review[\"datePublished\"]\n",
    "        except KeyError:\n",
    "\n",
    "            item[\"published_date\"] = next(iter(response.xpath(\n",
    "                f\"//div[contains(@id,'review_{review_id}')]/div/div/span[@class='ratingDate']/@title\"\"\").extract()),\n",
    "                                          None)\n",
    "\n",
    "        item[\"trip_type\"] = next(iter(response.xpath(\"//div[contains(@class,\"\n",
    "                                                     \"'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div\"\n",
    "                                                     \"/div/div/div[contains(@class,'noRatings')]/text()\").extract()),\n",
    "                                 None)\n",
    "\n",
    "        try:\n",
    "            item[\"trip_date\"] = next(iter(response.xpath(\"//div[contains(@class,\"\n",
    "                                                         \"'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div[\"\n",
    "                                                         \"contains(@class,'prw_reviews_stay_date_hsx')]/text()\").extract(\n",
    "\n",
    "            )), None)\n",
    "\n",
    "        except:\n",
    "\n",
    "            item[\"trip_date\"] = next(iter(response.xpath(\n",
    "                \"//div[contains(@id,'review_538163624')]/div/div/div[@data-prwidget-name='reviews_stay_date_hsx']/text()\").extract()),\n",
    "                                     None)\n",
    "\n",
    "        # user_info = response.xpath(\"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]\").extract()[0]\n",
    "        # item[\"unstructured\"] = user_info_splitter(user_info)\n",
    "\n",
    "        yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-22 15:37:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2019-01-22 15:37:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.2.2, Platform Darwin-18.2.0-x86_64-i386-64bit\n",
      "2019-01-22 15:37:56 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'tripadvisor2.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2019-01-22 15:37:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.tripadvisor.fr/Hotel_Review-g1572451-d775381-Reviews-Center_Parcs_Le_Lac_d_Ailette-Chamouille_Aisne_Hauts_de_France.html> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/scrapy/utils/defer.py\", line 102, in iter_errback\n",
      "    yield next(it)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py\", line 30, in process_spider_output\n",
      "    for x in result:\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py\", line 339, in <genexpr>\n",
      "    return (_set_referer(r) for r in result or ())\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n",
      "    return (r for r in result or () if _filter(r))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\n",
      "    return (r for r in result or () if _filter(r))\n",
      "  File \"<ipython-input-5-7d613dc2a459>\", line 27, in parse\n",
      "    next_page_number = 1+int(response.xpath('//span[@class=\"pageNum current disabled\"]').extract_first().replace(open_span, \"\").replace(close_span, \"\"))\n",
      "AttributeError: 'NoneType' object has no attribute 'replace'\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importing and reading data scraped\n",
    "\n",
    "If you've succeeded, you should see here a dataframe with 248 entries corresponding to the 248 reviews of the Center Parc you scraped. Congratulations ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6a8f6f4d9481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tripadvisor2.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Previewing DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 853\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "dfjson = pd.read_json('tripadvisor2.json')\n",
    "#Previewing DF\n",
    "dfjson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
