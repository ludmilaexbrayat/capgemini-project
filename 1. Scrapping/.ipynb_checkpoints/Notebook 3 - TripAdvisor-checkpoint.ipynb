{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Science for Business - Data Science Consulting - Session 2 \n",
    "\n",
    "### Notebook 3: Web Scraping with Scrapy: Getting reviews from TripAdvisor\n",
    "\n",
    "<u>Context</u>: This notebook was originally created by Capgemini. We adapted it to scrap data on the center Parc \"Le Lac d'Ailette\" (on TripAdvisor).\n",
    "\n",
    "<u>The main issue we faced when running this notebook</u>: changing the URL of the  listing to scrap triggered several errors. For instance, some tags were different, and we could not scrap the page number - which we use to stop the script. Also, we only managed to scrap 663 reviews. Not sure why, but this number corresponds to the total number of reviews in english (yet, we also have reviews in French...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.selector import Selector\n",
    "import sys\n",
    "from scrapy.http import Request\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# https://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "class HotelreviewsItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    rating = scrapy.Field()\n",
    "    review = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    trip_date = scrapy.Field()\n",
    "    trip_type = scrapy.Field()\n",
    "    published_date = scrapy.Field()\n",
    "    image_url = scrapy.Field()\n",
    "    hotel_type = scrapy.Field()\n",
    "    hotel_name = scrapy.Field()\n",
    "    hotel_adress = scrapy.Field()\n",
    "    price_range = scrapy.Field()\n",
    "    reviewer_id = scrapy.Field()\n",
    "    review_id = scrapy.Field()\n",
    "    review_language = scrapy.Field()\n",
    "    pid = scrapy.Field()\n",
    "    locid = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_info_splitter(raw_user_info):\n",
    "    \"\"\"\n",
    "\n",
    "    :param raw_user_info:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    user_info = {}\n",
    "\n",
    "    splited_info = raw_user_info.split()\n",
    "    for element in splited_info:\n",
    "        converted_element = get_convertible_elements_as_dic(element)\n",
    "        if converted_element:\n",
    "            user_info[converted_element[0]] = converted_element[1]\n",
    "\n",
    "    return user_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the JSon pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSon pipeline, you can rename the \"trust.jl\" to the name of your choice\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('tripadvisor2.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spider\n",
    "\n",
    "Now you know how to get data from one page, we want to automate the spider so it will crawl through all pages of reviews, ending with a full spider able to scrape every reviews of the selected parc. You will modify here the parse function since this is where you tell the spider to get the links and to follow them. <br>\n",
    "<b>To Do</b>: Complete the following code, to scrape all the reviews of one parc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySpider(CrawlSpider):\n",
    "    name = 'BasicSpider'\n",
    "    domain_url = \"https://www.tripadvisor.com\"\n",
    "    # allowed_domains = [\"https://www.tripadvisor.com\"]\n",
    "\n",
    "    start_urls = [\"https://www.tripadvisor.fr/Hotel_Review-g1572451-d775381-Reviews-Center_Parcs_Le_Lac_d_Ailette-Chamouille_Aisne_Hauts_de_France.html\"]\n",
    "    \n",
    "    #Custom settings to modify settings usually found in the settings.py file \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'tripadvisor2.json'                       # Used for pipeline 2\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        open_span = '<span class=\"pageNum current disabled\">'\n",
    "        close_span = '</span>'\n",
    "        \n",
    "        all_review_pages = response.xpath(\"//a[contains(@class,'pageNum') and contains(@class,'last')]/@data-offset\").extract()\n",
    "\n",
    "        next_reviews_page_url = \"https://www.tripadvisor.com\" + response.xpath(\"//a[contains(@class,'nav') and contains(@class,'next') and contains(@class,'primary')]/@href\").extract_first()\n",
    "\n",
    "        current_page_number = int(cleanhtml(response.xpath('//*[contains(@class,\"current\") and contains(@class, \"pageNum\")]').extract_first()))\n",
    "        last_page_number = int(cleanhtml(response.xpath('//*[contains(@class,\"last\") and contains(@class, \"pageNum\")]').extract_first()))\n",
    "\n",
    "        # Scrap all pages\n",
    "        if current_page_number < last_page_number:\n",
    "            yield scrapy.Request(next_reviews_page_url, callback=self.parse)\n",
    "\n",
    "        review_urls = []\n",
    "        for partial_review_url in response.xpath(\"//div[contains(@class,'quote')]/a/@href\").extract():\n",
    "            review_url = response.urljoin(partial_review_url)\n",
    "            if review_url not in review_urls:\n",
    "                review_urls.append(review_url)\n",
    "\n",
    "            yield scrapy.Request(review_url, callback=self.parse_review_page)\n",
    "\n",
    "    def parse_review_page(self, response):\n",
    "\n",
    "        item = HotelreviewsItem()\n",
    "\n",
    "        item[\"reviewer_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-memberid\").extract()),\n",
    "                                   None)\n",
    "        item[\"review_language\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-language\").extract()),\n",
    "                                       None)\n",
    "        item[\"review_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-reviewid\").extract()),\n",
    "                                 None)\n",
    "        item[\"review_id\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-reviewid\").extract()),\n",
    "                                 None)\n",
    "        item[\"pid\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-pid\").extract()),\n",
    "                           None)\n",
    "        item[\"locid\"] = next(iter(response.xpath(\n",
    "            \"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]/span/@data-locid\").extract()),\n",
    "                             None)\n",
    "\n",
    "        review_id = item[\"review_id\"]\n",
    "        review_url_on_page = response.xpath('//script[@type=\"application/ld+json\"]/text()').extract()\n",
    "        review = eval(review_url_on_page[0])\n",
    "\n",
    "        item[\"review\"] = review[\"reviewBody\"].replace(\"\\\\n\", \"\")\n",
    "        item[\"title\"] = review[\"name\"]\n",
    "        item[\"rating\"] = review[\"reviewRating\"][\"ratingValue\"]\n",
    "        item[\"image_url\"] = review[\"image\"]\n",
    "        item[\"hotel_type\"] = review[\"itemReviewed\"][\"@type\"]\n",
    "        item[\"hotel_name\"] = review[\"itemReviewed\"][\"name\"]\n",
    "        item[\"price_range\"] = review[\"itemReviewed\"][\"priceRange\"]\n",
    "        item[\"hotel_adress\"] = review[\"itemReviewed\"][\"address\"]\n",
    "        try:\n",
    "            item[\"published_date\"] = review[\"datePublished\"]\n",
    "        except KeyError:\n",
    "\n",
    "            item[\"published_date\"] = next(iter(response.xpath(\n",
    "                f\"//div[contains(@id,'review_{review_id}')]/div/div/span[@class='ratingDate']/@title\"\"\").extract()),\n",
    "                                          None)\n",
    "\n",
    "        item[\"trip_type\"] = next(iter(response.xpath(\"//div[contains(@class,\"\n",
    "                                                     \"'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div\"\n",
    "                                                     \"/div/div/div[contains(@class,'noRatings')]/text()\").extract()),\n",
    "                                 None)\n",
    "\n",
    "        try:\n",
    "            item[\"trip_date\"] = next(iter(response.xpath(\"//div[contains(@class,\"\n",
    "                                                         \"'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div[\"\n",
    "                                                         \"contains(@class,'prw_reviews_stay_date_hsx')]/text()\").extract(\n",
    "\n",
    "            )), None)\n",
    "\n",
    "        except:\n",
    "\n",
    "            item[\"trip_date\"] = next(iter(response.xpath(\n",
    "                \"//div[contains(@id,'review_538163624')]/div/div/div[@data-prwidget-name='reviews_stay_date_hsx']/text()\").extract()),\n",
    "                                     None)\n",
    "\n",
    "        # user_info = response.xpath(\"//div[contains(@class,'prw_reviews_resp_sur_h_featured_review')]/div/div/div/div/div[contains(@class,'prw_reviews_user_links_hs')]\").extract()[0]\n",
    "        # item[\"unstructured\"] = user_info_splitter(user_info)\n",
    "\n",
    "        yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-24 15:34:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2019-01-24 15:34:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2p  14 Aug 2018), cryptography 2.2.2, Platform Darwin-18.2.0-x86_64-i386-64bit\n",
      "2019-01-24 15:34:15 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'tripadvisor2.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importing and reading data scraped\n",
    "\n",
    "If you've succeeded, you should see here a dataframe with 248 entries corresponding to the 248 reviews of the Center Parc you scraped. Congratulations ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_adress</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>hotel_type</th>\n",
       "      <th>image_url</th>\n",
       "      <th>locid</th>\n",
       "      <th>pid</th>\n",
       "      <th>price_range</th>\n",
       "      <th>published_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_language</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>title</th>\n",
       "      <th>trip_date</th>\n",
       "      <th>trip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'@type': 'PostalAddress', 'streetAddress': '1...</td>\n",
       "      <td>Center Parcs Le Lac d'Ailette</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>https://media-cdn.tripadvisor.com/media/photo-...</td>\n",
       "      <td>775381</td>\n",
       "      <td>38673</td>\n",
       "      <td>115€ - 267€  (Selon les tarifs moyens d'une ch...</td>\n",
       "      <td>27 septembre 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Apr\\u00e8s une d\\u00e9sastreuse aventure au Bo...</td>\n",
       "      <td>619991006</td>\n",
       "      <td>fr</td>\n",
       "      <td>A70008728AC6B6105263C31212876BAB</td>\n",
       "      <td>tr\\u00e8s bon week end</td>\n",
       "      <td>août 2018</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'@type': 'PostalAddress', 'streetAddress': '1...</td>\n",
       "      <td>Center Parcs Le Lac d'Ailette</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>https://media-cdn.tripadvisor.com/media/photo-...</td>\n",
       "      <td>775381</td>\n",
       "      <td>38673</td>\n",
       "      <td>115€ - 267€  (Selon les tarifs moyens d'une ch...</td>\n",
       "      <td>18 janvier 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>Ambiance d\\u00e9tendue , une vraie d\\u00e9conn...</td>\n",
       "      <td>646844882</td>\n",
       "      <td>fr</td>\n",
       "      <td>E1D229008CB104D9A0B50E1C28400729</td>\n",
       "      <td>S\\u00e9jour agr\\u00e9able comme toujours ,une ...</td>\n",
       "      <td>mars 2018</td>\n",
       "      <td>A voyagé en famille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'@type': 'PostalAddress', 'streetAddress': '1...</td>\n",
       "      <td>Center Parcs Le Lac d'Ailette</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>https://media-cdn.tripadvisor.com/media/photo-...</td>\n",
       "      <td>775381</td>\n",
       "      <td>38673</td>\n",
       "      <td>115€ - 267€  (Selon les tarifs moyens d'une ch...</td>\n",
       "      <td>11 novembre 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>Premi\\u00e8re fois que nous allions \\u00e0 cen...</td>\n",
       "      <td>632573813</td>\n",
       "      <td>fr</td>\n",
       "      <td>56719A188FFAF310DB972EF10480F7DD</td>\n",
       "      <td>3,5 serait plus juste</td>\n",
       "      <td>juillet 2018</td>\n",
       "      <td>A voyagé en couple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'@type': 'PostalAddress', 'streetAddress': '1...</td>\n",
       "      <td>Center Parcs Le Lac d'Ailette</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>https://media-cdn.tripadvisor.com/media/photo-...</td>\n",
       "      <td>775381</td>\n",
       "      <td>38673</td>\n",
       "      <td>115€ - 267€  (Selon les tarifs moyens d'une ch...</td>\n",
       "      <td>3 octobre 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>G\\u00e9nial pour les enfants petits et grands ...</td>\n",
       "      <td>621674154</td>\n",
       "      <td>fr</td>\n",
       "      <td>05035FA5944AFAFFD00A7A4A4A6331D7</td>\n",
       "      <td>Endroit sympathique</td>\n",
       "      <td>avril 2018</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'@type': 'PostalAddress', 'streetAddress': '1...</td>\n",
       "      <td>Center Parcs Le Lac d'Ailette</td>\n",
       "      <td>LodgingBusiness</td>\n",
       "      <td>https://media-cdn.tripadvisor.com/media/photo-...</td>\n",
       "      <td>775381</td>\n",
       "      <td>38673</td>\n",
       "      <td>115€ - 267€  (Selon les tarifs moyens d'une ch...</td>\n",
       "      <td>17 janvier 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>Nous avons fait une r\\u00e9servation avec notr...</td>\n",
       "      <td>646623017</td>\n",
       "      <td>fr</td>\n",
       "      <td>0304614F0BFFA918916A51FD21624A4E</td>\n",
       "      <td>R\\u00e9servation f\\u00e9vrier 2019</td>\n",
       "      <td>janvier 2019</td>\n",
       "      <td>A voyagé en famille</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        hotel_adress  \\\n",
       "0  {'@type': 'PostalAddress', 'streetAddress': '1...   \n",
       "1  {'@type': 'PostalAddress', 'streetAddress': '1...   \n",
       "2  {'@type': 'PostalAddress', 'streetAddress': '1...   \n",
       "3  {'@type': 'PostalAddress', 'streetAddress': '1...   \n",
       "4  {'@type': 'PostalAddress', 'streetAddress': '1...   \n",
       "\n",
       "                      hotel_name       hotel_type  \\\n",
       "0  Center Parcs Le Lac d'Ailette  LodgingBusiness   \n",
       "1  Center Parcs Le Lac d'Ailette  LodgingBusiness   \n",
       "2  Center Parcs Le Lac d'Ailette  LodgingBusiness   \n",
       "3  Center Parcs Le Lac d'Ailette  LodgingBusiness   \n",
       "4  Center Parcs Le Lac d'Ailette  LodgingBusiness   \n",
       "\n",
       "                                           image_url   locid    pid  \\\n",
       "0  https://media-cdn.tripadvisor.com/media/photo-...  775381  38673   \n",
       "1  https://media-cdn.tripadvisor.com/media/photo-...  775381  38673   \n",
       "2  https://media-cdn.tripadvisor.com/media/photo-...  775381  38673   \n",
       "3  https://media-cdn.tripadvisor.com/media/photo-...  775381  38673   \n",
       "4  https://media-cdn.tripadvisor.com/media/photo-...  775381  38673   \n",
       "\n",
       "                                         price_range     published_date  \\\n",
       "0  115€ - 267€  (Selon les tarifs moyens d'une ch...  27 septembre 2018   \n",
       "1  115€ - 267€  (Selon les tarifs moyens d'une ch...    18 janvier 2019   \n",
       "2  115€ - 267€  (Selon les tarifs moyens d'une ch...   11 novembre 2018   \n",
       "3  115€ - 267€  (Selon les tarifs moyens d'une ch...     3 octobre 2018   \n",
       "4  115€ - 267€  (Selon les tarifs moyens d'une ch...    17 janvier 2019   \n",
       "\n",
       "   rating                                             review  review_id  \\\n",
       "0       4  Apr\\u00e8s une d\\u00e9sastreuse aventure au Bo...  619991006   \n",
       "1       5  Ambiance d\\u00e9tendue , une vraie d\\u00e9conn...  646844882   \n",
       "2       3  Premi\\u00e8re fois que nous allions \\u00e0 cen...  632573813   \n",
       "3       4  G\\u00e9nial pour les enfants petits et grands ...  621674154   \n",
       "4       2  Nous avons fait une r\\u00e9servation avec notr...  646623017   \n",
       "\n",
       "  review_language                       reviewer_id  \\\n",
       "0              fr  A70008728AC6B6105263C31212876BAB   \n",
       "1              fr  E1D229008CB104D9A0B50E1C28400729   \n",
       "2              fr  56719A188FFAF310DB972EF10480F7DD   \n",
       "3              fr  05035FA5944AFAFFD00A7A4A4A6331D7   \n",
       "4              fr  0304614F0BFFA918916A51FD21624A4E   \n",
       "\n",
       "                                               title      trip_date  \\\n",
       "0                             tr\\u00e8s bon week end      août 2018   \n",
       "1  S\\u00e9jour agr\\u00e9able comme toujours ,une ...      mars 2018   \n",
       "2                             3,5 serait plus juste    juillet 2018   \n",
       "3                                Endroit sympathique     avril 2018   \n",
       "4                 R\\u00e9servation f\\u00e9vrier 2019   janvier 2019   \n",
       "\n",
       "             trip_type  \n",
       "0                 None  \n",
       "1  A voyagé en famille  \n",
       "2   A voyagé en couple  \n",
       "3                 None  \n",
       "4  A voyagé en famille  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjson = pd.read_json('tripadvisor2.json')\n",
    "#Previewing DF\n",
    "dfjson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(663, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjson.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
